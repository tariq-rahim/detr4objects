{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c08bab",
   "metadata": {},
   "source": [
    "### Object Dectection Using DETR ( Transformer Based )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4b09a",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from transformers import DetrImageProcessor\n",
    "import os\n",
    "import supervision as sv\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import DetrForObjectDetection\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b093164",
   "metadata": {},
   "source": [
    "Loading image data with a custom Dataset ( i.e. Coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "dataset = r'custom detr\\dataset_path' # Replace with your dataset path\n",
    "\n",
    "ANNOTATION_FILE_NAME = \"annotation_file.json\"\n",
    "TRAIN_DIRECTORY = os.path.join(dataset, \"train\")\n",
    "VAL_DIRECTORY = os.path.join(dataset, \"valid\")\n",
    "TEST_DIRECTORY = os.path.join(dataset, \"test\")\n",
    "\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(\n",
    "        self, \n",
    "        image_directory_path: str, \n",
    "        image_processor, \n",
    "        train: bool = True\n",
    "    ):\n",
    "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
    "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)        \n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "\n",
    "TRAIN_DATASET = CocoDetection(image_directory_path=TRAIN_DIRECTORY, image_processor=image_processor, train=True)\n",
    "VAL_DATASET = CocoDetection(image_directory_path=VAL_DIRECTORY, image_processor=image_processor, train=False)\n",
    "TEST_DATASET = CocoDetection(image_directory_path=TEST_DIRECTORY, image_processor=image_processor, train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
    "print(\"Number of validation examples:\", len(VAL_DATASET))\n",
    "print(\"Number of test examples:\", len(TEST_DATASET))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb9186",
   "metadata": {},
   "source": [
    "Find Number of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fae5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = TRAIN_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k,v in categories.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae07cb",
   "metadata": {},
   "source": [
    "Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random image ID from COCO dataset\n",
    "image_ids = TRAIN_DATASET.coco.getImgIds()\n",
    "image_id = random.choice(image_ids)\n",
    "print(f'Image #{image_id}')\n",
    "\n",
    "# Load image info and annotations\n",
    "image_info = TRAIN_DATASET.coco.loadImgs(image_id)[0]\n",
    "annotations = TRAIN_DATASET.coco.imgToAnns[image_id]\n",
    "\n",
    "# Load image using OpenCV\n",
    "image_path = os.path.join(TRAIN_DATASET.root, image_info['file_name'])\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert COCO bbox to xyxy and get class IDs\n",
    "xyxy = []\n",
    "class_ids = []\n",
    "\n",
    "for ann in annotations:\n",
    "    x, y, w, h = ann['bbox']\n",
    "    xyxy.append([x, y, x + w, y + h])  # COCO format is [x, y, width, height]\n",
    "    class_ids.append(ann['category_id'])\n",
    "\n",
    "# Build class ID to label mapping\n",
    "categories = TRAIN_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k, v in categories.items()}\n",
    "labels = [id2label[class_id] for class_id in class_ids]\n",
    "\n",
    "# Create Detections object with labels\n",
    "detections = sv.Detections(\n",
    "    xyxy=np.array(xyxy),\n",
    "    class_id=np.array(class_ids),\n",
    "    data={\"labels\": labels}\n",
    ")\n",
    "\n",
    "# Annotate image with bounding boxes and labels\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "annotated_image = box_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "\n",
    "# Convert BGR to RGB for display with matplotlib\n",
    "image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Show image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Image #{image_id}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580812f9",
   "metadata": {},
   "source": [
    "Turn custom loaded images into DataLoader's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f63eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': encoding['pixel_values'],\n",
    "        'pixel_mask': encoding['pixel_mask'],\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4, shuffle=True)\n",
    "VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=4)\n",
    "TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
